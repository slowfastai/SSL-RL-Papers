# SSL-RL-Papers

> A curated collection of papers combining Self-Supervised Learning (SSL) with Reinforcement Learning (RL), toward autonomous agents in the Era of Experience.
> *Inspired by* **"Welcome to the Era of Experience"** *(Silver & Sutton, 2025)*

---

## ğŸŒ± Motivation

Reading *Welcome to the Era of Experience* has been deeply inspiring. The essay crystallized a critical insight: methods like **RLHF** (Reinforcement Learning from Human Feedback) and **RLVR** (Reinforcement Learning with Verifiable Rewards), while highly influential, are still rooted in **human-labeled data**. This situates them within the **Era of Human Data**, and broadly aligns them with **supervised learning paradigms**.

To build truly **general-purpose reinforcement learning (RL)** systems at scale, we must move beyond human-annotated signals and embrace the **Era of Experience** â€” where agents improve via continuous, autonomous interaction with the world.

In this context, I believe **Self-Supervised Learning (SSL)** combined with **Reinforcement Learning (RL)** â€” particularly verifier-driven or value-based approaches â€” represents a promising and foundational direction. This repo curates key research at this intersection, aiming to accelerate the emergence of autonomous, self-improving agents that learn from experience.

## ğŸ“Œ Key Topics

* Representation learning for RL
* Reward-free or unsupervised RL
* World model pretraining
* SSL-based exploration strategies
* Unsupervised skill discovery
* Planning with learned representations

## ğŸ“„ Paper List


(ğŸ“Œ *More papers coming soon â€” organized by task, domain, and technique*)


## ğŸ¤ Contribution

Feel free to open pull requests for new papers, summaries, or framework comparisons. Discussions, suggestions, and stars welcome â­

## ğŸ“œ License

This repository is open-source under the MIT License.
